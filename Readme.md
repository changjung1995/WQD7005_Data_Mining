## WQD 7005 Data Mining Assignment

### Title : Application of Data Mining in Price Movement of Cryptocurrency

### Team Member: 
### 1. Tan Chang Jung
### https://github.com/changjung1995/WQD7005_Data_Mining

### 2. Tan Sia Hong
### https://github.com/jasonhong94/-WQD7005_Data_Mining

### Summary for the assignment (from milestone 1 to 5)

##### 1. Milestone 1 (https://github.com/changjung1995/WQD7005_Data_Mining/tree/master/Milestone_One)
##### Presentation video: https://www.youtube.com/watch?v=fU2Db8uiP8U&t=1078s
In Milestone 1, I was crawled the price of cryptocurrencies from https://coinmarketcap.com/. The first 20 top cryptocurrencies was crawled by using Python BeautifulSoup. There are 6 columns exist in the dataset, which are close, high, low, open, volume and market capacity. The dataset was cleaned, and the data types were changed accordingly. Lastly, the cleaned dataset was save as csv files.

![image](https://user-images.githubusercontent.com/55917583/85192293-8e74b900-b2f4-11ea-8f9b-7cbd1a2ffbf4.png)

##### 2. Milestone 1 (https://github.com/changjung1995/WQD7005_Data_Mining/tree/master/Milestone_Two)
##### Presentation video: https://drive.google.com/file/d/1Edhkywf2lKtzASOhj_xPABT-_Jh4zHB_/view?usp=sharing
In Milestone 2, the crawled data are required to store in the data warehouse. We need data warehouse instead of RDBMS database as data warehouse is designed to separate the big data analysis and query process. This is designed to facilitate decision making by consolidate and analyze information at different levels. I was installing Hortonworks Sandbox, as Hortonworks comes with Apache Hadoop and Apache Hive on top of the Hadoop. Hortonworks is an open source, as it faster the deployment process. At the end of installation, I was successfully load the data into Hive database with mysql as database schema.

![image](https://user-images.githubusercontent.com/55917583/85192441-1c50a400-b2f5-11ea-8861-fd5435bee79d.png)

